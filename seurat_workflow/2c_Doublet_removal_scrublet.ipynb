{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries/packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(... or whatever you python people call them ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scrublet as scr\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from time import gmtime, strftime\n",
    "from sinfo import sinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-07-15 11:00:39'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `param_files/scrublet_params.py` to load the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'param_files/scrublet_params.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = os.path.join(os.getcwd(),'../')\n",
    "proj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alevin_dir = f'{proj_dir}analyses/doublets/filtered_inputs/'\n",
    "alevin_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_dir\n",
    "# import socket\n",
    "# curr_machine = socket.gethostname()\n",
    "# if curr_machine == \"mentok\":\n",
    "#     proj_dir = \"/mnt/data/backups/cluster_backups/cbrg\"+proj_dir\n",
    "#     alevin_dir = f'{proj_dir}analyses/doublets/filtered_inputs/'\n",
    "# proj_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imagine you'll handle this with rufus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(proj_dir,'analyses/doublets/scrublet/')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrublet doesn't like compressed files for input, so they need to be uncompressed. I imagine you'll handle this within rufus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are still compressed\n",
      "Decompressing ... \n",
      "Files are still compressed\n",
      "Decompressing ... \n"
     ]
    }
   ],
   "source": [
    "for dir_path in glob.glob(f'{alevin_dir}*'):\n",
    "    os.chdir(os.path.join(alevin_dir,dir_path))\n",
    "    if os.path.isfile('matrix.mtx.gz'):\n",
    "        print (\"Files are still compressed\")\n",
    "        print (\"Decompressing ... \")\n",
    "        os.system('gunzip *.gz')\n",
    "    else:\n",
    "        print (\"Files are already uncompressed.\")\n",
    "    os.chdir(alevin_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List input directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/data/backups/cluster_backups/cbrg/project/cncb/shared/proj075/analyses/doublets/filtered_inputs/v2',\n",
       " '/mnt/data/backups/cluster_backups/cbrg/project/cncb/shared/proj075/analyses/doublets/filtered_inputs/v3']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(output_dir)\n",
    "myList = glob.glob(f'{alevin_dir}*')\n",
    "myList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Scrublet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in myList:\n",
    "\n",
    "    #dir_name = dir_path[78:]\n",
    "    dir_name = dir_path.split('/')[-1]\n",
    "    print('\\n\\n\\n\\nProcessing: ',dir_path,'\\n\\n')\n",
    "    print('Loading data...')\n",
    "    counts_matrix = scipy.io.mmread(dir_path + '/matrix.mtx').T.tocsc()\n",
    "    genes = np.array(scr.load_genes(dir_path + '/features.tsv', delimiter = '\\t', column = 1))\n",
    "    print('Done.\\n')\n",
    "    print('\\n\\nCounts matrix shape: {} rows, {} columns'.format(counts_matrix.shape[0], counts_matrix.shape[1]))\n",
    "    print('Number of genes in gene list: {}'.format(len(genes)))\n",
    "    exp_doub_rate = 0.008*counts_matrix.shape[0]/1000\n",
    "    print('Expected doublet rate: ', exp_doub_rate)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    print('Detecting doublets...')\n",
    "\n",
    "    \n",
    "    doublet_scores = np.zeros((counts_matrix.shape[0],len(pcs)))\n",
    "    predicted_doublets = np.zeros((counts_matrix.shape[0],len(pcs)))\n",
    "    z_scores = np.zeros((counts_matrix.shape[0],len(pcs)))\n",
    "    \n",
    "    for i, pc in enumerate(pcs):\n",
    "        print('\\n\\n\\n\\nCurrent number of PCAs: ',pc,'\\n\\n')\n",
    "        scrub = scr.Scrublet(counts_matrix, \n",
    "                             expected_doublet_rate = exp_doub_rate, \n",
    "                             sim_doublet_ratio = sim_doub_rat)\n",
    "        temp_scores, temp_doublets = scrub.scrub_doublets(min_counts = min_count, \n",
    "                                                          min_cells = 3, \n",
    "                                                          min_gene_variability_pctl = vgp, \n",
    "                                                          n_prin_comps = pc,\n",
    "                                                          log_transform = log_trans,\n",
    "                                                          mean_center = mean_cent,\n",
    "                                                          normalize_variance = norm_var,\n",
    "                                                          synthetic_doublet_umi_subsampling = syn_doub_umi)\n",
    "        \n",
    "        temp_doublets = scrub.call_doublets(threshold = my_thresh)\n",
    "        temp_z_scores = scrub.z_scores_\n",
    "        \n",
    "        doublet_scores[:,i] = temp_scores\n",
    "        predicted_doublets[:,i] = temp_doublets\n",
    "        z_scores[:,i] = temp_z_scores\n",
    "        \n",
    "        print(f'\\nIdentified {temp_doublets[temp_doublets == True].shape[0]} doublets...\\n\\n')\n",
    "        %matplotlib inline\n",
    "        p1 = scrub.plot_histogram();\n",
    "        plt.show()\n",
    "        print('Running UMAP...')\n",
    "        scrub.set_embedding('UMAP', scr.get_umap(scrub.manifold_obs_, 10, min_dist = 0.3))\n",
    "        print('Plotting UMAP...')\n",
    "        print('    Predicted Doublets and Doublet Score')\n",
    "        %matplotlib inline\n",
    "        p2 = scrub.plot_embedding('UMAP', order_points = True);\n",
    "        plt.show()\n",
    "        print('    Predicted Doublets and Z-Score')\n",
    "        %matplotlib inline\n",
    "        p3 = scrub.plot_embedding('UMAP', order_points = True, score = 'zscore');\n",
    "        plt.show()\n",
    "        print('Done.\\n')\n",
    "\n",
    "    print('Done.\\n')\n",
    "\n",
    "    barcodes = pd.read_csv(f'{dir_path}/barcodes.tsv',sep = \"\\t\",header = None)    \n",
    "    \n",
    "    doublet_scores_df = pd.DataFrame(doublet_scores, index = barcodes[0], columns = pcs)\n",
    "    z_scores_df = pd.DataFrame(z_scores, index = barcodes[0], columns = pcs)\n",
    "    predicted_doublets_df = pd.DataFrame(predicted_doublets, index = barcodes[0], columns = pcs)\n",
    "    \n",
    "    \n",
    "    print('Saving data...')\n",
    "    doublet_scores_df.to_csv(f'{dir_name}_doublet_scores.csv', index = True, header = True, sep = ',')\n",
    "    z_scores_df.to_csv(f'{dir_name}_z_scores.csv', index = True, header = True, sep = ',')\n",
    "    predicted_doublets_df.to_csv(f'{dir_name}_predicted_doublets.csv', index = True, header = True, sep = ',') \n",
    "    print('Done.\\n\\n\\n\\n')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
